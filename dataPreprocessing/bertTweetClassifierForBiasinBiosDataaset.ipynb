{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92799190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijaythirunavukarasu/Documents/RealThesisImplementation/ThesisProject1/ThesisImplemenationenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    get_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c828f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e61b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de22235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(CrossEntropyLoss):\n",
    "    def __init__(self, alpha=1.0, gamma=3.0, reduction='mean', ignore_index=-100, label_smoothing=0.1):\n",
    "        super().__init__(weight=None, reduction=reduction, ignore_index=ignore_index, label_smoothing=label_smoothing)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = super().forward(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158626c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': 'bias_in_bios_gender_dataset.csv'})\n",
    "dataset = dataset['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed9ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NLP-LTU/bertweet-large-sexism-detector'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54aba8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b3783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 13136.96 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 17490.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f3309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    report = classification_report(labels, predictions, target_names=['unbiased', 'biased'], output_dict=True)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    return {'accuracy': acc, 'f1_macro': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54eeac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ca654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'layer' in name and int(name.split('.')[3]) < 8:\n",
    "        param.requires_grad = False\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fb2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        class_weights = torch.tensor([1.0, 1.5]).to(logits.device)  # Boost biased if under-recalled\n",
    "        loss_fn = FocalLoss(alpha=1.0, gamma=3.0)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fa9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,  # Small for memory on large data/MPS; increase to 16+ if possible\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    greater_is_better=True,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=False,\n",
    "    bf16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39797597",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "num_training_steps = len(tokenized_datasets['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=training_args.warmup_steps, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74b03ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/v67_cz3j5p9gdz9s5pkxyync0000gn/T/ipykernel_94820/1886282468.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc3b001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 2:13:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.889477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>0.896468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>0.908465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.907976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[875 113]\n",
      " [108 904]]\n",
      "Classification Report:\n",
      " {'unbiased': {'precision': 0.8901322482197355, 'recall': 0.8856275303643725, 'f1-score': 0.8878741755454084, 'support': 988.0}, 'biased': {'precision': 0.8888888888888888, 'recall': 0.8932806324110671, 'f1-score': 0.8910793494332183, 'support': 1012.0}, 'accuracy': 0.8895, 'macro avg': {'precision': 0.8895105685543121, 'recall': 0.8894540813877199, 'f1-score': 0.8894767624893134, 'support': 2000.0}, 'weighted avg': {'precision': 0.889503108398327, 'recall': 0.8895, 'f1-score': 0.8894959935326402, 'support': 2000.0}}\n",
      "Confusion Matrix:\n",
      " [[914  74]\n",
      " [133 879]]\n",
      "Classification Report:\n",
      " {'unbiased': {'precision': 0.8729703915950334, 'recall': 0.9251012145748988, 'f1-score': 0.8982800982800982, 'support': 988.0}, 'biased': {'precision': 0.9223504721930745, 'recall': 0.8685770750988142, 'f1-score': 0.8946564885496183, 'support': 1012.0}, 'accuracy': 0.8965, 'macro avg': {'precision': 0.897660431894054, 'recall': 0.8968391448368565, 'f1-score': 0.8964682934148582, 'support': 2000.0}, 'weighted avg': {'precision': 0.8979567123776423, 'recall': 0.8965, 'f1-score': 0.8964465517564754, 'support': 2000.0}}\n",
      "Confusion Matrix:\n",
      " [[881 107]\n",
      " [ 78 934]]\n",
      "Classification Report:\n",
      " {'unbiased': {'precision': 0.9186652763295099, 'recall': 0.8917004048582996, 'f1-score': 0.9049820236260914, 'support': 988.0}, 'biased': {'precision': 0.8972142170989433, 'recall': 0.9229249011857708, 'f1-score': 0.9098879688261081, 'support': 1012.0}, 'accuracy': 0.9075, 'macro avg': {'precision': 0.9079397467142266, 'recall': 0.9073126530220352, 'f1-score': 0.9074349962260997, 'support': 2000.0}, 'weighted avg': {'precision': 0.9078110403588432, 'recall': 0.9075, 'f1-score': 0.9074644318972999, 'support': 2000.0}}\n",
      "Confusion Matrix:\n",
      " [[889  99]\n",
      " [ 84 928]]\n",
      "Classification Report:\n",
      " {'unbiased': {'precision': 0.9136690647482014, 'recall': 0.8997975708502024, 'f1-score': 0.9066802651708312, 'support': 988.0}, 'biased': {'precision': 0.9036027263875365, 'recall': 0.9169960474308301, 'f1-score': 0.9102501226091221, 'support': 1012.0}, 'accuracy': 0.9085, 'macro avg': {'precision': 0.908635895567869, 'recall': 0.9083968091405162, 'f1-score': 0.9084651938899766, 'support': 2000.0}, 'weighted avg': {'precision': 0.908575497537705, 'recall': 0.9085, 'f1-score': 0.9084866130346063, 'support': 2000.0}}\n",
      "Confusion Matrix:\n",
      " [[892  96]\n",
      " [ 88 924]]\n",
      "Classification Report:\n",
      " {'unbiased': {'precision': 0.9102040816326531, 'recall': 0.902834008097166, 'f1-score': 0.9065040650406504, 'support': 988.0}, 'biased': {'precision': 0.9058823529411765, 'recall': 0.9130434782608695, 'f1-score': 0.9094488188976378, 'support': 1012.0}, 'accuracy': 0.908, 'macro avg': {'precision': 0.9080432172869148, 'recall': 0.9079387431790178, 'f1-score': 0.9079764419691441, 'support': 2000.0}, 'weighted avg': {'precision': 0.9080172869147659, 'recall': 0.908, 'f1-score': 0.9079941104922861, 'support': 2000.0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.04366940427981317, metrics={'train_runtime': 8021.8569, 'train_samples_per_second': 4.986, 'train_steps_per_second': 0.623, 'total_flos': 1.863862726656e+16, 'train_loss': 0.04366940427981317, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c653d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./fine_tuned_bertTweetClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd22ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path='./fine_tuned_bertTweetClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelUd = AutoModelForSequenceClassification.from_pretrained(new_model_path)\n",
    "tokenizerUd = AutoTokenizer.from_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "086d30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelUd.config.id2label = {0: 'Unbiased', 1: 'Biased'}\n",
    "modelUd.config.label2id = {'Unbiased': 0, 'Biased': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e2788ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bias_classifier_remapped/tokenizer_config.json',\n",
       " './fine_tuned_bias_classifier_remapped/special_tokens_map.json',\n",
       " './fine_tuned_bias_classifier_remapped/vocab.json',\n",
       " './fine_tuned_bias_classifier_remapped/merges.txt',\n",
       " './fine_tuned_bias_classifier_remapped/added_tokens.json',\n",
       " './fine_tuned_bias_classifier_remapped/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelUd.save_pretrained('./fine_tuned_bias_classifier_remapped')\n",
    "tokenizerUd.save_pretrained('./fine_tuned_bias_classifier_remapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "359de4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier2 = pipeline('text-classification', model='./fine_tuned_bias_classifier_remapped', tokenizer='./fine_tuned_bias_classifier_remapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bffc3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier1 = pipeline('text-classification', model='./fine_tuned_bertTweetClassifier', device=0 if device.type == 'mps' else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8f56901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.9065775275230408}]\n",
      "[{'label': 'sexist', 'score': 0.9001874327659607}]\n",
      "[{'label': 'not sexist', 'score': 0.8941965699195862}]\n",
      "[{'label': 'sexist', 'score': 0.7785928249359131}]\n",
      "[{'label': 'sexist', 'score': 0.8025675415992737}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier1(\"Only Men can become actors in America not women.Women cannot get good roles in movies made in america. Women are expected to stick to working in kitchen more often\"))  # Biased test\n",
    "print(classifier1(\"John is a successful actor in America, but women like Mary cannot become actors because only men are suited for the role\"))\n",
    "print(classifier1(\"American actors are diverse.\"))  # Unbiased test\n",
    "print(classifier1(\"Only women can work as nurses and cook and househelps\")) \n",
    "print(classifier1(\"Men are always strong and women are always weak, this is the truth and women should accept it\")) # Biased test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb6f6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Biased', 'score': 0.9065775275230408}]\n",
      "[{'label': 'Biased', 'score': 0.9001874327659607}]\n",
      "[{'label': 'Unbiased', 'score': 0.8941965699195862}]\n",
      "[{'label': 'Biased', 'score': 0.7785928249359131}]\n",
      "[{'label': 'Biased', 'score': 0.8025675415992737}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classifier2(\"Only Men can become actors in America not women.Women cannot get good roles in movies made in america. Women are expected to stick to working in kitchen more often\"))  # Biased test\n",
    "print(classifier2(\"John is a successful actor in America, but women like Mary cannot become actors because only men are suited for the role\"))\n",
    "print(classifier2(\"American actors are diverse.\"))  # Unbiased test\n",
    "print(classifier2(\"Only women can work as nurses and cook and househelps\")) \n",
    "print(classifier2(\"Men are always strong and women are always weak, this is the truth and women should accept it\")) # Biased test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622f18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'not sexist', 'score': 0.951004147529602}]\n",
      "[{'label': 'sexist', 'score': 0.9647285342216492}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier1(\"She graduated with honors in 2012. Having more than 5 years of diverse experiences, especially in NURSE PRACTITIONER, Pamela A Boyd affiliates with many hospitals including Eastside Medical Center, Clearview Regional Medical Center, and cooperates with other doctors and specialists in many medical groups including Greater Gwinnett Internal Medicine Associates LLC, Grayson Primary Care LLC. Call Pamela A Boyd on phone number (678) 225-4999 for more information and advises or to book an appointment.\"))  # Biased test\n",
    "print(classifier1(\"Prior to joining UCL, he has worked as a Catastrophe Risk Modeller at AIR Worldwide and as a Research Associate at the University of California, Irvine. His recent research focuses on developing methods and tools for multi-hazard risk and resilience assessment of critical infrastructure in developing countries.\"))  # Unbiased test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b575385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.904565155506134}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier1(\"Mr. Chad Allen Walker's NPI Number is #1730145368 and has been listed in the NPI registry for 10 years. Mr. Chad Allen Walker's practice location is listed as: 300 W 10Th Ave Columbus, OH 43210-1280 and can be reached via phone at (614) 366-7594.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0aabd0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
    "import torch\n",
    "model = AutoModelForSequenceClassification.from_pretrained('NLP-LTU/bertweet-large-sexism-detector')\n",
    "tokenizer = AutoTokenizer.from_pretrained('NLP-LTU/bertweet-large-sexism-detector') \n",
    "classifier2 = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# label_pred = 'not sexist' if prediction == 0 else 'sexist' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ff4e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.9985693693161011}]\n"
     ]
    }
   ],
   "source": [
    "prediction=classifier2(\"Every woman wants to be a model. It's codeword for 'I get everything for free and people want me' \")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f785f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.987933874130249}]\n",
      "[{'label': 'sexist', 'score': 0.9904969930648804}]\n",
      "[{'label': 'not sexist', 'score': 0.9995484948158264}]\n",
      "[{'label': 'sexist', 'score': 0.995790958404541}]\n",
      "[{'label': 'sexist', 'score': 0.9985925555229187}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier2(\"Only Men can become actors in America not women.Women cannot get good roles in movies made in america. Women are expected to stick to working in kitchen more often\"))  # Biased test\n",
    "print(classifier2(\"John is a successful actor in America, but women like Mary cannot become actors because only men are suited for the role\"))\n",
    "print(classifier2(\"American actors are diverse.\"))  # Unbiased test\n",
    "print(classifier2(\"Only women can work as nurses and cook and househelps\")) \n",
    "print(classifier2(\"Men are always strong and women are always weak, this is the truth and women should accept it\")) # Biased test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "deb6a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'not sexist', 'score': 0.9984695315361023}]\n",
      "[{'label': 'not sexist', 'score': 0.9992302656173706}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier2(\"She graduated with honors in 2012. Having more than 5 years of diverse experiences, especially in NURSE PRACTITIONER, Pamela A Boyd affiliates with many hospitals including Eastside Medical Center, Clearview Regional Medical Center, and cooperates with other doctors and specialists in many medical groups including Greater Gwinnett Internal Medicine Associates LLC, Grayson Primary Care LLC. Call Pamela A Boyd on phone number (678) 225-4999 for more information and advises or to book an appointment.\"))  # Biased test\n",
    "print(classifier2(\"Prior to joining UCL, he has worked as a Catastrophe Risk Modeller at AIR Worldwide and as a Research Associate at the University of California, Irvine. His recent research focuses on developing methods and tools for multi-hazard risk and resilience assessment of critical infrastructure in developing countries.\"))  # Unbiased test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "924e58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.9370615482330322}]\n",
      "[{'label': 'sexist', 'score': 0.9157705307006836}]\n",
      "[{'label': 'sexist', 'score': 0.5840442776679993}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier1(\"Only a man can act well in films , not women\"))  # Biased (stereotype)\n",
    "print(classifier1(\"Women can only cook\"))  # Unbiased\n",
    "print(classifier1(\"only men can become engineers\"))  # Biased (StereoSet-like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2a98aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sexist', 'score': 0.7287744879722595}]\n",
      "[{'label': 'not sexist', 'score': 0.6844674944877625}]\n",
      "[{'label': 'sexist', 'score': 0.8942158818244934}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier1(\"Math is only for men\"))  # Unbiased (anti-stereotype)\n",
    "print(classifier1(\"Math is  for everyone\")) \n",
    "print(classifier1(\"Math is only for women\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThesisImplemenationenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
